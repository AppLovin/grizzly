<?xml version="1.0" encoding="UTF-8"?>
<section version="5.0" xml:id="core-config"
         xmlns="http://docbook.org/ns/docbook"
         xmlns:xlink="http://www.w3.org/1999/xlink"
         xmlns:xi="http://www.w3.org/2001/XInclude"
         xmlns:svg="http://www.w3.org/2000/svg"
         xmlns:m="http://www.w3.org/1998/Math/MathML"
         xmlns:html="http://www.w3.org/1999/xhtml"
         xmlns:db="http://docbook.org/ns/docbook">
  <title>Core Configuration</title>

  <para>The primary points of configuration of the core framework are that of
  the Transport instances and their associated thread pools. The ability to
  configure both entities is possible via the NIOTransportBuilder.</para>

  <section>
    <title>Transport Configuration</title>

    <para>Just as there are concrete NIOTransport implementations for TCP and
    UDP, so too are there two concrete NIOTransportBuilder implementations.
    Each NIOTransportBuilder implementation exposes configurable features
    unique to each transport. The following describes configuration properties
    common to all NIOTransports and then describes the properties for the TCP
    and UDP NIOTransport implementations.</para>

    <table>
      <title>NIOTransportBuilder Properties</title>

      <tgroup cols="2">
        <tbody>
          <row>
            <entry>workerThreadPoolConfig</entry>

            <entry>This property exposes a ThreadPoolConfig instance that
            allows configuration of the worker thread pool used by the
            transport that will be constructed by this builder. Note:
            depending on the IOStrategy being used, this value may be
            null.</entry>
          </row>

          <row>
            <entry>IOStrategy</entry>

            <entry>Sets the IOStrategy that will be used by this transport.
            Note that changing this value before the transport has been
            started may have an impact on the return value of the
            workerThreadPoolConfig property. If no value is explicitly set,
            the WorkerThreadIOStrategy will be employed. See the section on
            <link xlink:href="iostrategies.xml"
            xml:id="ios001">IOStrategies</link> for specifics on each
            concreate IOStrategy included with Grizzly 2.0.</entry>
          </row>

          <row>
            <entry>memoryManager</entry>

            <entry>Sets the MemoryManager to be used by this transport. If no
            value is explicitly set, the MemoryManager used will be the
            NIOTransportBuilder.DEFAULT_MEMORY_MANAGER. See the section on
            <link xlink:href="memory.xml" xml:id="mem001">Memory
            Management</link> for specifics on the MemoryManager
            system.</entry>
          </row>

          <row>
            <entry>selectorHandler</entry>

            <entry>Sets the SelectorHandler to be used by this transport. If
            no value is explicitly set, the SelectorHandler used wil be the
            NIOTransportBuilder.DEFAULT_SELECTOR_HANDLER. See the section on
            <link xlink:href="transports-connections.xml"
            xml:id="tc001">Transports and Connections</link> for specifics on
            the SelectorHandler.</entry>
          </row>

          <row>
            <entry>selectionKeyHandler</entry>

            <entry>Sets the SelectionKeyHandler to be used by this transport.
            If no value is explicitly set, the SelectionKeyHandler used will
            be the NIOTransportBuilder.DEFAULT_SELECTION_KEY_HANDLER. See the
            section on <link xlink:href="transports-connections.xml"
            xml:id="tc002">Transports and Connections</link> for specifics on
            the SelectionKeyHandler.</entry>
          </row>

          <row>
            <entry>attributeBuilder</entry>

            <entry>Sets the AttributeBuilder to be used by this transport. If
            no value is explicitly set, the AttributeBuilder used will be the
            NIOTransportBuilder.DEFAULT_ATTRIBUTE_BUILDER.</entry>
          </row>

          <row>
            <entry>NIOChannelDistributor</entry>

            <entry>Sets the NIOChannelDistributor used by this transport. See
            the section on <link xlink:href="transports-connections.xml?"
            xml:id="tc003">Transports and Connections</link> for specifics on
            the NIOChannelDistributor.</entry>
          </row>

          <row>
            <entry>processor</entry>

            <entry>Sets the Processor used by this transport.</entry>
          </row>

          <row>
            <entry>processorSelector</entry>

            <entry>Sets the ProcessorSelector used by this transport.</entry>
          </row>

          <row>
            <entry>readBufferSize</entry>

            <entry>Sets the size of the Buffer that will be allocated,
            per-connection, to read incoming data.</entry>
          </row>

          <row>
            <entry>writeBuffersSize</entry>

            <entry>Sets the size of the Buffer that will be applicated,
            per-connection, to write outgoing data.</entry>
          </row>
        </tbody>
      </tgroup>
    </table>

    <table>
      <title>TCPNIOTransportBuilder Properties</title>

      <tgroup cols="2">
        <tbody>
          <row>
            <entry>clientSocketSoTimeout</entry>

            <entry>Enable/disable SO_TIMEOUT with the specified timeout, in
            milliseconds (client mode).</entry>
          </row>

          <row>
            <entry>connectionTimeout</entry>

            <entry>Time in milliseconds for how long establishing a connection
            can take before the operation times out.</entry>
          </row>

          <row>
            <entry>keepAlive</entry>

            <entry>Enable/disable SO_KEEPALIVE.</entry>
          </row>

          <row>
            <entry>linger</entry>

            <entry>Enable/disable SO_LINGER with the specified linger time in
            seconds. The maximum timeout value is platform specific. The
            setting only affects socket close.</entry>
          </row>

          <row>
            <entry>reuseAddress</entry>

            <entry>Enable/disable the SO_REUSEADDR socket option. When a TCP
            connection is closed the connection may remain in a timeout state
            for a period of time after the connection is closed (typically
            known as the TIME_WAIT state or 2MSL wait state). For applications
            using a well known socket address or port it may not be possible
            to bind a socket to the required SocketAddress if there is a
            connection in the timeout state involving the socket address or
            port.</entry>
          </row>

          <row>
            <entry>serverConnectionBacklog</entry>

            <entry>Specifies the maximum pending connection queue
            length.</entry>
          </row>

          <row>
            <entry>serverSocketSoTimeout</entry>

            <entry>Enable/disable SO_TIMEOUT with the specified timeout, in
            milliseconds (server mode).</entry>
          </row>

          <row>
            <entry>tcpNoDelay</entry>

            <entry>Enable/disable TCP_NODELAY (disable/enable Nagle's
            algorithm).</entry>
          </row>

          <row>
            <entry>temporarySelectorIO</entry>

            <entry>Allows the specification of a TemporarySelectorIO instance
            to aid in the simulation of blocking IO.</entry>
          </row>
        </tbody>
      </tgroup>
    </table>

    <table>
      <title>UDPNIOTransportBuilder Properties</title>

      <tgroup cols="2">
        <tbody>
          <row>
            <entry>connectionTimeout</entry>

            <entry>Time in milliseconds for how long establishing a connection
            can take before the operation times out.</entry>
          </row>

          <row>
            <entry>reuseAddress</entry>

            <entry>Enable/disable the SO_REUSEADDR socket option. When a TCP
            connection is closed the connection may remain in a timeout state
            for a period of time after the connection is closed (typically
            known as the TIME_WAIT state or 2MSL wait state). For applications
            using a well known socket address or port it may not be possible
            to bind a socket to the required SocketAddress if there is a
            connection in the timeout state involving the socket address or
            port.</entry>
          </row>

          <row>
            <entry>temporarySelectorIO</entry>

            <entry>Allows the specification of a TemporarySelectorIO instance
            to aid in the simulation of blocking IO.</entry>
          </row>
        </tbody>
      </tgroup>
    </table>
  </section>

  <section>
    <title>Thread Pool Configuration</title>

    <para>Grizzly's thread pool configuration is managed by the
    ThreadPoolConfig object:</para>

    <table>
      <title>ThreadPoolConfig Properties</title>

      <tgroup cols="2">
        <tbody>
          <row>
            <entry>queue</entry>

            <entry>The task Queue implementation to be used.</entry>
          </row>

          <row>
            <entry>queueLimit</entry>

            <entry>The maximum number of pending tasks that may be
            queued.</entry>
          </row>

          <row>
            <entry>threadFactory</entry>

            <entry>The ThreadFactory that the pool will use to create new
            Threads.</entry>
          </row>

          <row>
            <entry>poolName</entry>

            <entry>The name of this thread pool.</entry>
          </row>

          <row>
            <entry>priority</entry>

            <entry>The priority to be assigned to each thread. This will
            override any priority assigned by the specified
            ThreadFactory.</entry>
          </row>

          <row>
            <entry>corePoolSize</entry>

            <entry>The initial number of threads that will be present with the
            thread pool is created.</entry>
          </row>

          <row>
            <entry>maxPoolSize</entry>

            <entry>The maximum number threads that may be maintained by this
            thread pool.</entry>
          </row>

          <row>
            <entry>keepAliveTime</entry>

            <entry>The maximum time a thread may be allowed to run. Custom
            time units can be used.</entry>
          </row>
        </tbody>
      </tgroup>
    </table>

    <para>The thread pool configuration is fairly straight forward. However,
    it should be noted that Grizzly, internally, has several thread pool
    implementations: SyncThreadPool, FixedThreadPool, and
    QueueLimitedThreadPool. Which implementation is chosen is based on the
    configuration. The following sections describe each of the thread pool
    implementations.</para>

    <section>
      <title>FixedThreadPool</title>

      <para>This pool will be selected when the queueLimit property is less
      than zero, and the max and core pool sizes are the same. The
      FixedThreadPool has no syncronization when executing tasks, so it offers
      better performance.</para>
    </section>

    <section>
      <title>QueueLimitedThreadPool</title>

      <para>This pool will be selected when the queueLimit property is greater
      than zero, and the max and core pool sizes are the same. The
      QueueLimitedThreadPool is an extension of the FixedThreadPool, so if
      offers the same benefits of the FixedThreadPool without having an
      unbounded task queue.</para>
    </section>

    <section>
      <title>SyncThreadPool</title>

      <para>This pool will be selected when none of the criteria for the other
      thread pools apply. This thread pool does have syncronization to have
      precise controll over the decision of thread creation.</para>
    </section>
  </section>

  <section>
    <title>Examples</title>

    <para>Here are some examples of using the TCPNIOTransportBuilder to
    configure the Transport and/or thread pool.</para>

    <programlisting language="java">final TCPNIOTransportBuilder builder = TCPNIOTranportBuilder.newInstance(); <co
        linkends="ex1-1" xml:id="ex1new" />
final TCPNIOTransport transport = builder.build(); <co linkends="ex1-2"
        xml:id="ex1bld" /></programlisting>

    <calloutlist>
      <callout arearefs="ex1new" xml:id="ex1-1">
        <para>Create a new TCPNIOTransportBuilder instance.</para>
      </callout>

      <callout arearefs="ex1bld" xml:id="ex1-2">
        <para>Creates a new TCPNIOTransport using defaults. Adjustments to the
        Transport configuration can still be made at this point as long as the
        Transport has not been started.</para>
      </callout>
    </calloutlist>

    <programlisting language="java">
final TCPNIOTransportBuilder builder = TCPNIOTransportBuilder.newInstance(); <co linkends="ex2-1" xml:id="ex2-1-co" />
final TCPNIOTransport transport = builder.setIOStrategy(new SameThreadIOStrategy()).setTcpNoDelay(true).build(); <co linkends="ex2-2" xml:id="ex2-2-co" />
    </programlisting>

    <calloutlist>
      <callout arearefs="ex2-1-co" xml:id="ex2-1">
        <para>Create a new TCPNIOTransportBuilder instance.</para>
      </callout>

      <callout arearefs="ex2-2-co" xml:id="ex2-2">
        <para>Creates a new TCPNIOTransport using the SameThreadIOStrategy and
        setting tcp no-delay to true. Notice you can chain configuration calls
        with the builder implementation.</para>
      </callout>
    </calloutlist>

    <programlisting language="java">final TCPNIOTransportBuilder builder = TCPNIOTransportBuilder.newInstance(); <co
        linkends="ex3-1" xml:id="ex3-1-co" />
final ThreadPoolConfig config = builder.getWorkerThreadPoolConfig(); <co
        linkends="ex3-2" xml:id="ex3-2-co" />
config.setCorePoolSize(5).setMaxPoolSize(5).setQueueLimit(-1); <co
        linkends="ex3-3" xml:id="ex3-3-co" />
final TCPNIOTransport transport = builder.build(); <co linkends="ex3-4"
        xml:id="ex3-4-co" /></programlisting>

    <calloutlist>
      <callout arearefs="ex3-1-co" xml:id="ex3-1">
        <para>Create a new TCPNIOTransportBuilder instance.</para>
      </callout>

      <callout arearefs="ex3-2-co" xml:id="ex3-2">
        <para>Obtains the ThreadPoolConfig. Note that depending on the
        IOStrategy being used, this may return null. Since the default
        IOStrategy is WorkerThreadIOStrategy, this call will return a non-null
        value.</para>
      </callout>

      <callout arearefs="ex3-3-co" xml:id="ex3-3">
        <para>Update the worker thread pool configuration to have no queue
        limit, and have the same core and max pool size values. This will
        bring the FixedThreadPool implementation into play when the runtime is
        started.</para>
      </callout>

      <callout arearefs="ex3-4-co" xml:id="ex3-4">
        <para>Creates a new TCPNIOTransport based on the builder
        configuration.</para>
      </callout>
    </calloutlist>
  </section>
</section>
